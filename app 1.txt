from flask import Flask, request, jsonify
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import load_model
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

model = load_model("quotex_signal_model.h5")
FEATURES = ["open", "high", "low", "close", "volume"]
SEQ_LEN = 10

def prepare_sequence(data):
    df = pd.DataFrame(data)
    df = df[FEATURES]
    if len(df) < SEQ_LEN:
        raise ValueError("Not enough candles")
    seq = df.iloc[-SEQ_LEN:].values
    return np.expand_dims(seq, axis=0)

@app.route("/predict", methods=["POST"])
def predict():
    try:
        data = request.get_json()
        sequence = prepare_sequence(data["candles"])
        pred = model.predict(sequence)[0][0]
        signal = "Buy" if pred >= 0.5 else "Sell"
        return jsonify({"prediction": signal, "confidence": round(float(pred), 4)})
    except Exception as e:
        return jsonify({"error": str(e)}), 400

@app.route("/batch", methods=["POST"])
def batch_predict():
    try:
        file = request.files["file"]
        df = pd.read_csv(file)
        df = df[FEATURES]
        predictions = []
        for i in range(len(df) - SEQ_LEN):
            seq = df.iloc[i:i+SEQ_LEN].values
            seq = np.expand_dims(seq, axis=0)
            pred = model.predict(seq)[0][0]
            predictions.append("Buy" if pred >= 0.5 else "Sell")
        return jsonify({"predictions": predictions})
    except Exception as e:
        return jsonify({"error": str(e)}), 400

@app.route("/", methods=["GET"])
def home():
    return "Quotex AI Signal Backend is Running âœ…"

if __name__ == "__main__":
    app.run()
